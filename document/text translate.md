# <center>基于网络的端到端的可训练的面向任务的对话系统</center>

## <center>摘要</center>

训练机器与人类自然地沟通来完成任务是充满挑战的。当前，开发面向任务的对话系统要求创建多个模块，这些模块要么需要大量的人工，要么需要大量的已标注的数据来解决数据学习问题。本文介绍一种基于神经网络，输入输出都是文本，端到端的可训练的面向目标的对话系统，通过一种全新的方式收集对话数据，一种新的的pipe-line Wizard-of-Oz框架。这种方法允许我们简单地开发对话系统，而不需要对手上的任务做太多的假设。结果展示了这个模型在餐馆搜索任务中可以针对主题自然地与人类沟通，并帮助他们完成任务。

## 1.介绍

搭建一个类似酒店预订或者技术支持服务的面向任务的对话系统是困难的，因为特定的应用场景，常常可训练的数据是有限的。为了缓和这个问题，最近使用机器学习来设计面向任务的对话系统的人员，把问题转化为了Partially Observable Markov Decision Process(部分可观察的马尔可夫决策过程POMDP)模型，目的是利用强化学习通过与用户在线交流来实时地训练对话策略。然而，语言理解和语言生成模型仍然基于监督学习，所以需要语料库来训练。此外，为了使RL容易处理，必须仔细设计状态和行为空间，因为这有可能限制模型的表达能力和学习能力。同时，该模型的reward functions很难设计，在运行时评估效果也异常困难。

在这个方面的另一个例子是，seq2seq的学习已经引发了一些尝试，他们建立端到端的可训练的非面向任务的对话系统。这一类的方法把对话系统看作是源到目标序列的转化问题，应用编码网络把用户的输入转换成一个分布式向量，其中包含了语义，然后再加上一个解码网络生成系统响应。这些模型显然需要大量的数据进行训练。这类模型可以拿来创建有效的聊天机器人系统，但是缺乏解决特定领域任务的能力，比如，和数据库交互，在响应中加入有用的信息。

本文中，提出了一个基于神经网络的面向任务的对话系统模型，综合了上面两个系统的优缺点；该模型是端到端可训练的，但仍然通过模块链接而成；它并不直接对用户的目标建模，尽管如此，它仍然可以学习完成目标任务---提供相关和适当的回应；它通过数据库属性的显示表示来实现高任务成功率，而且它允许用户模糊输入，因为它使用分布式向量表示用户意图；它使用去词汇化和权重搭配的策略来减少训练模型所需要的数据量，但如果有更多的数据可用当然更好。本文还证明了，即使数据只有几个百对话，该模型仍然可以很好地完成任务。

为了训练模型，本文介绍了一种新的pipeline数据收集方式，其灵感来自Wizard-of-Oz paradigm，通过众包的方式收集人类对话语料库。我们发现这个过程非常简单，快速，但只需要很少的开发成本。

## 2.模型

把对话看做是seq2seq的映射问题，利用对话历史和当前数据库的搜索结果可以使效果更好，其中映射问题使用seq2seq架构，对话历史使用belief trackers（信念追踪），数据库信息使用数据库操作，如图1。系统将用户的输入转化成两种表示方式，一种是分布式表示，由意图网络生成；一种是概率分布，由一系列belief trackers生成的belief状态组成的slot值对生成。然后，在belief状态中最可能的值来搜索数据库，搜索结果和意图表示以及belief状态被策略网络整合生成单个向量，作为下一个系统的输入。然后，使用回应生成网络，结合前面生成的向量，通过骨架形式的输入生成部分词是数值的句子。最后，通过查询数据库把这些数值转换成词语，生成骨架句子形式。细节在下面展开

### 2.1 意图网络

意图网络可以被看做是一个seq2seq学习框架的encoder，它的工作是把每个时刻的一串单词的输入表示成一个分布式向量。比如，LSTM网络，隐藏层的最后一层作为向量表示。

或者，卷积神经网络也可以做到，他可以替代LSTM网络作为encoder，所以两者我们都使用了。因为所有代表特定信息的slotvalue是去词汇化的，被编码的向量可以被看做是一个分布式意图表示，用来代替传统的面向任务的对话系统中的手工编码对话行为。

### 2.2 belief trackers

belief tracking也被称为对话状态跟踪，它提供面向任务的口语对话系统的核心。当下最先进的belief trackers使用判别模型，例如循环神经网络（RNN）可以直接把ASR假设映射到belief状态。即使本文主要研究基于文本的对话系统，但仍然把belief trackers作为本文的核心，因为：1.它可以把任意格式的自然语言句子映射到一系列固定的slot-value对，然后才可以作为数据库的查询条件。这可以看做是一个简易版本的语义分析器。2.通过持续跟踪对话状态，可以避免从原始输入学习不必要的复杂的长期的依赖。3.通过灵活的权重平衡策略可以大大地降低模型训练的样本数量要求，4.它的固有的健壮性可以简化对口语系统的扩展。

把用户的每一次输入看做一个新的证据，belief tracker的任务是针对每个信息slot *s*维护一个多项式分布*p*，*p*的取自*v*，*v*属于*Vs*，针对请求slot一个二进制分布。本体知识图谱G的每个slot有自己的特定的tracker，每个tracker是乔丹类型的（从输出层到隐藏层的循环）RNN，配合CNN特征抽取器，如图2。为每个值*v*绑定RNN权重，但是变化特征f当更新pre-softmax激活g，等式如下。p theta代表用户未提到的概率，在时刻t可以使用g theta来代替g_v计算。为了对语义上下建模，特征向量ftvcnn是两个CNN级联的衍生特征，一个是在处理时刻t用户的输入u，另一个是在处理时刻t-1的机器回应结果mt-1，ut和mt-1用一个N维的词向量表示，衍生自one-hot编码的输入。为了让tracker感知到一个slot或者value去词汇化，不仅仅在句子的输出层应用CNN，而且在中间层的n-gram嵌入层，决定于每句话的去词汇化位置。如果观察到多个匹配，相应的词嵌入相加。另一方面，如果没有对应的匹配值，则填0。为了持续跟踪去词汇化的单词的位置，每次卷积运算之前，句子的两边填充0。向量的数量决定于每一层的过滤器的大小。图2显示了提取多个特定位置特征层的整个过程。

上文描述的belief tracker基于xxx提出的理论，再做了一些修改：1.只有信息槽和请求槽的概率输出。2.重复性内存块被删除，因为在这里它起不到任何作用，3.n-gram特征提取器被CNN提取器替代。介绍了基于slot的belief trackers，相比纯粹的end2end系统，该系统添加了一系列中间层标签。下文将会展示这些tracker组件是完成任务的关键之一。我们展示了他们引入的注释需求通过一个新颖的pipe-lined Woz数据收集框架，减轻工作量。

### 2.3 策略网络和数据库操作

<font size=5> **数据库操作**</font>  基于belief trackers的输出pts，数据库查询语句qt形成如下，xxxx，Si是信息slots的集合。然后这个查询语句被应用于数据库，在数据库实体上创建一个二进制真值向量xt，其中1代表对应实体被查询到（因此它与最可能的belief状态一致）。此外，x如果不是全0，则维护一个相关联的实体指针，用来标识随机选择的匹配实体之一。如果当前实体不再符合搜索条件，则实体指针将被更新；否则保持不变。被查询到的实体将会被用于构建系统响应，在2.4节阐述。  
<font size=5> **策略网络**</font>  策略网络可以被看做是将系统其他模块绑定在一起的胶水。它的输出是一个代表系统动作的向量ot，它的输入包括来自意图网络的zt，belief状态pts，和数据库真值向量xt。因为生成网络只生成合适的句子形式，单个的概率值是不重要的，但是把下面三个部分加在一起形成一个总的belief向量pts拔：概率和，用户不关心该slot的概率，以及该slot未被提及的概率。类似地，真值向量xt，重要的是匹配的数量，而不是单个被匹配的个体。因此，该向量被压缩为6-bin 1-hot（6个等级one-hot编码？）的向量Xt拔，它代表了在数据库中的不同匹配度（0个匹配，1个匹配....或者5个匹配）。最后，策略网络的输出来自三个方向的矩阵变换，xxxx

### 2.4 生成网络

生成网络使用动作向量ot作用于一个语言生成器。它生成模板句子，建立在语言模型概率上，一个单词一个单词地生成，xxxxx，其中LSTMj是一个条件LSTM操作，wtj表示最近的一次输出单词（单词，去词汇化的slot名，或者去词汇化的slot值），ht（j-1）是隐藏层。一旦输出单词队列生成，通用单词会被他们的真实值代替：1.通过在表面形式列表中随机采样代替去词汇slot，比如，<s.food>表示食物或者食物的种类，2.使用数据库指针当前选中的实体的实际属性值代替去词汇slot。这有些类似于潜在预测网络，通过指针网络集合将实体指定的信息转化为响应。

<font size=5> **细心的生成网络**</font>  并不是直接从一个静态的动作向量Ot解码输出，基于注意力的机制，在每个步骤j，可以动态地聚合源词嵌入向量。本文，我们尝试使用注意力的机制整合belief tracker的状态，比如，Ot在每个步骤j都被计算。xxxxx

## 3.Woz数据收集

通过统计的方式训练对话系统的最大瓶颈是收集合适的训练数据，对于面向任务的对话系统尤其正确。xxx已为现有的语料库做了分类，为发展会话代理。这样的预料库对于滚雪球学习可能是有用的，但是对于基于主题的面向任务的对话系统是必要的。为了缓和这个问题，我们提出了一个新的WOZ众包版本，用于收集特定领域的语料库。

基于给定的实体论，我们在xx网站上设计了两个网页，一个用于向导，一个用于用户。用户的任务是指定他们一定要找到的特定实体的特点（比如，在北部一个中国餐馆），而且要求输入自然语言的句子来完成任务。向导使用一个表格记录上一轮用户对话传递的信息（比如，价格区间=中国，地址=北部），然后一个搜索表格展示匹配的所有可能的结果。注意，这些表格包括所有的需要用来训练基于slot的belief trackers的标签。这些表格在向导提交新的资料之后自动更新。基于最新的表格，向导输出一个合适的系统响应，然后对话继续。

为了实现大规模并行的数据采集工作，避免传统的WOZ固有的分散的延迟性，用户和向导只需要对每个对话仅贡献一次。为了确保一致性和连贯性，用户和向导必须在他们发言之前回顾对话历史。这样对话处理就可以流水线工作。大量的对话可以被同时激活，任何工作者都不要等待对话的另一方的回应。尽管多个工作人员同时服务一个对话，我们观察到对话通常是连贯的，但多样。另外，这类轮流的数据收集策略看起来像鼓励工作人员学习和纠正前面工作人员的操作。

本文设计了一个系统，辅助用户在剑桥找到一个饭店。有三个信息slot（食物，价格，地址），用户可以用来约束搜索结果；六个请求slot，（地址，电话，邮政编码，加上三个信息slot），用户可以询问已经提供的一个饭店的信息。在数据库有99个饭店，我们大概运行了三天，跑了3000次HIT（人工智能任务），收集了1500个对话轮次。整理之后，我们大概保留了680个对话（有些是不完整的）。收集数据集的成本一共是400美元。

## 4. 实验研究

<font size=5>**训练**</font>  训练被分成两个方面。第一，belief trackers的参数theta b使用跟踪标签yts和预测标签pts的交叉熵误差，对于整个模型来讲，有三个信息slot和七个请求slot。

拥有固定的tracker参数，模型剩下的部分theta b撇，使用生成网络语言模型交叉熵误差，xxx，输出单词目标和预测结果。我们把每个对话看做一个批处理，使用随机梯度下降和L2正则化来训练模型。语料库被分成三个部分，训练，校验，测试，3:1:1。将正则化参数和梯度学习率设置为1，在验证集上可以提前结束。所有的隐藏层的大小被设置成50，所有的权重被随机初始化为-0.3和0.3，包括词嵌入。词汇表的大小大概为500，包括输入和输出，但是去除了低频词和可以去词汇化的词。我们使用了三个词汇表层，所有的过滤器大小为3,。Pooling操作只在最后的卷积层之后才被应用。

<font size=5>**解码**</font>  为了解码无长度差别，我们解码每个系统响应，基于单个单词概率的平均log。

作为对比，我们同样调查了MMI标准来增加多样性，添加额外的评分在去词汇化的位置来更好地完成任务。权重解码策略如下式。xxxx。我们对评分函数rt使用了一种简单的启发式方法，该方法旨在奖励提供适当信息的人，惩罚提供未经请求的信息的人。我们使用定向搜索，定向宽度为10，当句子的结尾单词找到时结束。为了实现语言的灵活性，我们搜索直到找到五个候选者，随机选择其中一个。

<font size=5>**tracker性能**</font>  表1展示了tracker性能的评估。因为去词汇化，包括CNN类型的tracker和n-gram类型的tracker都实现高准确率，但是n-gram trackers的召回率很差。这个结果表明，相对简单的n-gram模型，CNN类型的tracker可以更好地推理出长距离依赖和复杂句法结构的句子。

<font size=5>**基于语料库的评估**</font>  我们估计end2end系统，使用基于语料库的评估，该模型预测在保留的测试集中的每个系统响应。我们使用了三种评估度，BLEU分（一个候选和五个候选）。实体匹配率，和目标任务成功率。计算实体匹配率，通过每个对话最终选中的实体是否匹配用户指定的任务。对话被标记为成功与否，1.提供的实体命中，2.系统回应了所有用户的相关信息请求。计算BLEU分，在词汇化之前，评价句子的模板相似度。

图2展示了基于语料库评估的5次随机初始网络的平均结果。baseline栏展示了两个baseline模型：第一个是简单的轮次等级的seq2seq模型，第二个引入了一个循环来模拟上下文历史的依赖性。可以看到，循环的引入可以提高BLEU分数。然而，baseline的任务成功率和匹配率不能被计算，因为模型没有对数据库做任何准备。

变体栏展示了两个变体模型。第一个，没有使用请求slot，仅仅使用了信息slot。因此，对用户的请求slot建模的重担落到了意图网络上。我们发现，没有显示地模拟用户的请求，模型的表现很差，任务完成率不到30%，即使它可以提供正确的实体。更多的数据表现可能为更好，然而，我们发现引入一个显式的内部的语义表示在完整得到模型中表现更好。第二个变体，LSTM意图网络被一个CNN替代。我们认为这是因为CNN通过几个局部特征把意图编码进来了，但是缺乏句子的全局信息，这很容易导致过拟合。

完整模型栏展示了不同解码策略的模型表现。第一行展示了使用等式13的平均似然概率，第二行使用了等式14的配置了权重解码策略的结果。我们可以看到，权重解码策略并没有提高BLEU分，但是它提高了任务成功率。对性能提高贡献最大的是Rt项，因为它在解码时插入了其他额外的特定任务的信息。尽管如此，最有效和优雅的方式是使用att动态的整个tracker beliefs来提高性能。他对于提高BLEU分的帮助不大，但是在任务成功率上有很大的提高。最后，我们可以合并权重分配解码和att得到更好的性能。

顺便说一句，我们使用t-SNE来生成一个降维之后的动作嵌入向量Ot的可视化图形，使用前三个单词作为标签，如图3。我们可以看到基于系统意图类型的清晰集群，即使我们没有显式地使用对话动作对他们建模。

<font size=5>**人工评估**</font>  为了评估运维效果，我们通过在xxx上招募付费受试者进行了测试。每个裁判员被要求完成一个特定的任务，并评估模型的效果。我们评估了主观成功率、感知理解能力和回答自然度，评分范围为1-5分。我们使用完整的模型，并测试了245组对话。我们可以看到主观成功率高达98%，代表系统可以完成大部分的任务。另外，感知理解能力和自然度都站在4到5之间。

同样，我们对比了NN模型和HDC之间的差别，HDC是指baseline系统配合手工操作，由手工语义解析，基于规则的策略和belief tracker，和一个基于模板的生成器。测试结果在表4。结果显示，HDC有着95%的任务成功率，代表它是一个强大的baseline，即使大部分组件是手工操作的。一共测试了164哥对话，NN模型在任何角度都比HDC强。即使两个系统都有着类似的任务成功率，NN系统效率更高，有着更迷人的对话，对话轮次更少。另外，理解能力和自然度，NN系统大大的强于HDC，这表示学习系统比手工系统更加自然。

## 5. 结论和未来的工作

本文提出了一种新颖的基于神经网络框架的面向任务的对话系统。模型使用end2end的训练方式，使用两个监督标签，适度的语料库训练数据。本文还提出了一种新颖的众包数据收集框架，启发于Woz范式。我们证明了流水线并行的组织数据收集框架可以得到高质量的面向任务的对话数据，而且又快花费又少。

NN对话系统的实验评估结果表明，学习模型可以在人类话题中的，与人类高效自然地沟通并完成特定的任务。据我们所知，这是第一个end2end的NN模型，可以面向任务的对话中组织有意义的对话。

然而，还有很多工作需要完成。我们当前的系统是基于文本的，这就导致不能直接处理噪声语音识别输入，也不能在不确定的情况下要求用户确认。事实上，这个模型在更大的更宽泛的领域的扩展度是一个待解决的问题，我们将在未来的工作中继续解决这些问题。